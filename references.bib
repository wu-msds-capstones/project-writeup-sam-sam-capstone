@online{Beck2025,
  title       = {A '60s–flavored band blew up on Spotify. They're AI.},
  author      = {Ethan Beck},
  year        = {2025},
  month       = {July 8},
  note        = {The Washington Post},
  url         = {Error! Filename not specified.},
  description = {A detailed report on “The Velvet Sundown,” an entirely AI–generated ’60s–style band whose tracks topped Spotify’s Viral 50 before revealing their non‑human origins, illustrating the challenges of detecting AI music in real time.}
}

@online{Barlow2025,
  title       = {Apple and Spotify are sleepwalking into an AI music crisis—and The Velvet Sundown mess shows they need to act fast},
  author      = {Graham Barlow},
  year        = {2025},
  month       = {July 3},
  note        = {TechRadar},
  url         = {https://www.techradar.com/computing/artificial-intelligence/apple-and-spotify-are-sleepwalking-into-an-ai-music-crisis-and-the-velvet-sundown-mess-shows-they-need-to-act-fast?utm_source=chatgpt.com},
  description = {An op‑ed arguing that major streaming platforms must implement “artist‑centric guardrails” to label AI‑generated tracks, citing The Velvet Sundown as a wake‑up call.}
}

@online{Musically2025,
  title       = {Key Quotes from Michael Nash’s July 8, 2025 Keynote},
  author      = {{MusicAlly}},
  year        = {2025},
  month       = {July 8},
  note        = {MusicAlly},
  url         = {https://musically.com/2025/07/08/umgs-michael-nash-ai-can-be-fundamental-to-the-future-of-music/},
  description = {A curated list of quotes from UMG EVP Michael Nash emphasizing the need to center artists in AI music policy, uphold copyright, and create “new creative and commercial opportunities.”}
}

@online{Reuters2025,
  title       = {Resurgence of music securitization attracts investors, but emerging risks like AI remain considerations},
  author      = {{Reuters}},
  year        = {2025},
  month       = {July 8},
  note        = {Reuters},
  url         = {https://www.reuters.com/legal/legalindustry/resurgence-music-securitization-issuer-investor-appeal-data-driven-era-2025-07-08/},
  description = {A financial report on the booming music royalty securitization market, noting growing issuance and flagging AI‑generated music as a new risk factor.}
}

@online{PressReynolds2025,
  title       = {How AI Wreaked Havoc on the Lo‑Fi Beat Scene},
  author      = {Ethan Beck and others},
  year        = {2025},
  month       = {July 2},
  note        = {Pitchfork},
  url         = {https://pitchfork.com/thepitch/how-ai-wreaked-havoc-on-the-lo-fi-beat-scene/?utm_source=chatgpt.com},
  description = {A feature on how AI‑generated “soporific dreck” has flooded YouTube and lo‑fi communities, including user voices lamenting “lost soul” and calls for streaming‑service regulation.}
}

@article{Dervakos2021,
  title       = {Heuristics for evaluation of AI-generated music},
  author      = {Emmanouil Dervakos and Georgios Filandrianos and Giorgos Stamou},
  journal     = {ICPR 2021 Poster},
  year        = {2021},
  url         = {https://ailb-web.ing.unimore.it/icpr/media/posters/11986.pdf},
  description = {Proposes a harmony‑based heuristic framework for objective evaluation of generative AI music in the symbolic domain, leveraging tone networks and tonic coordinate systems.}
}

@article{Sarmento2024,
  title       = {Between the AI and Me: Analysing listeners’ perspectives on AI‑ and human‑composed progressive metal music},
  author      = {Pedro Sarmento and Jonas Loth and Meinard Barthet},
  journal     = {arXiv},
  year        = {2024},
  url         = {https://arxiv.org/abs/2407.21615},
  description = {A listening study comparing AI‑ vs. human‑composed progressive metal, finding genre‑congruence via fine‑tuning but a persistent listener preference for human works despite near‑chance distinguishability.}
}

@article{Afchar2025,
  title       = {Detecting generative AI in music: First public AI‑music detector and its challenges},
  author      = {Darius Afchar and Isam Issam and C{\'e}dric Pr{\'e}vost},
  journal     = {arXiv},
  year        = {2025},
  url         = {https://arxiv.org/html/2501.10111v1},
  description = {Introduces the first public AI‑music detector trained on real vs. reconstructed audio with 99.8% accuracy, and discusses its limitations in robustness and generalization.}
}

@online{York2023,
  title       = {AI-generated music inferior to human-composed music},
  author      = {University of York},
  year        = {2023},
  url         = {https://www.york.ac.uk/news-and-events/news/2023/research/ai-generated-music-inferior-to-human-composed/},
  description = {A press release reporting that human‑composed excerpts scored significantly higher in listener ratings than AI‑generated ones, and warning of inadvertent copyright infringement by AI models.}
}

@online{Schneider2025,
  title       = {AI music is more common – and harder to catch – than ever},
  author      = {Lauren Schneider},
  year        = {2025},
  month       = {May 19},
  note        = {Scienceline},
  url         = {https://scienceline.org/2025/05/ai-music-is-more-common-and-harder-to-catch-than-ever/},
  description = {Examines the subtleties of AI music detection, reports on deep‑feature datasets, legal suits over training data, and the limits of classifier generalization.}
}

@article{Noh2025,
  title       = {Harmony and personality: Analyzing connections between AI-generated music preference and personal traits},
  author      = {Michael Noh and Caitlyn Kim},
  journal     = {Nursing and Healthcare Science Journal},
  year        = {2025},
  url         = {https://nhsjs.com/2025/harmony-and-personality-analyzing-connections-between-ai-generated-music-preference-and-personal-traits/},
  description = {Finds that perceived AI‑composed music is rated lower than human, that overall identification accuracy hovers around 57%, and that openness to experience correlates with decreased accuracy.}
}

@online{Misra2022,
  title       = {An AI model to differentiate AI-generated music from human-composed music},
  author      = {Siddarth Misra},
  year        = {2022},
  note        = {Independent Project Mentorship},
  url         = {https://independent-project-mentorship.netlify.app/assets/pdfs/2ededfe6e527c0b86f86b57d56647c1400ba9a27.pdf},
  description = {Describes a Transformer‑encoder, MLP, and LSTM approach on Jukebox data, achieving 96% accuracy in distinguishing AI vs. human compositions using MFCC features.}
}

@online{WikipediaAI,
  title       = {Music and artificial intelligence},
  author      = {{Wikipedia contributors}},
  note        = {Wikipedia, The Free Encyclopedia},
  url         = {https://en.wikipedia.org/wiki/Music_and_artificial_intelligence},
  description = {An overview of AI in music—from rule‑based systems of the 1950s to modern text‑to‑music platforms—covering technical milestones, legal issues, and notable applications.}
}

@article{Flexer2006,
  title       = {Combination of spectral and rhythmic similarity feature spaces for music classification},
  author      = {Andreas Flexer and Daniel Schnitzer and Gerhard Widmer},
  journal     = {OeFAI TR-2006-09, Austrian Research Institute for Artificial Intelligence},
  year        = {2006},
  url         = {https://ofai.at/papers/oefai-tr-2006-09.pdf},
  description = {Develops a probabilistic “product rule” to combine GMM‑based spectral and tempo‑based rhythmic classifiers, boosting ballroom‑dance music classification accuracy from ~33%/59% individually to ~67% combined.}
}

@techreport{Bulayenko2022,
  title       = {How can EU copyright law protect AI musical outputs?},
  author      = {Iryna Bulayenko and others},
  institution = {SSRN},
  year        = {2022},
  url         = {https://ssrn.com/abstract=4072806},
  description = {A doctrinal and empirical study surveying EU copyright frameworks, stakeholder practices, and proposing a four‑step originality test to guide AI‑generated music protection.}
}
